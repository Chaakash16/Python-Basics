{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJSJwABVq7Sur1/eo9AuhI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaakash16/Python-Basics/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical**"
      ],
      "metadata": {
        "id": "Fc7rT3_zZmH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. What is Logistic Regression, and how does it differ from Linear Regression?**  \n",
        "Logistic Regression is a classification algorithm used to predict categorical outcomes (e.g., spam vs. not spam). It applies the **sigmoid function** to map predictions between 0 and 1. In contrast, Linear Regression predicts continuous values.  \n",
        "\n",
        "### **2. What is the mathematical equation of Logistic Regression?**  \n",
        "The equation is:  \n",
        "\\[\n",
        "P(Y=1) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n)}}\n",
        "\\]  \n",
        "where **P(Y=1)** is the probability of the positive class, and **β** are the regression coefficients.  \n",
        "\n",
        "### **3. Why do we use the Sigmoid function in Logistic Regression?**  \n",
        "The sigmoid function maps any real-valued number to a probability between **0 and 1**, which helps in classification tasks by converting linear outputs into probabilities.  \n",
        "\n",
        "### **4. What is the cost function of Logistic Regression?**  \n",
        "The cost function used is the **Log Loss (Binary Cross-Entropy)**:  \n",
        "\\[\n",
        "J(\\theta) = - \\frac{1}{m} \\sum \\left[ y \\log(h) + (1 - y) \\log(1 - h) \\right]\n",
        "\\]  \n",
        "where \\( h \\) is the predicted probability. It penalizes incorrect predictions.  \n",
        "\n",
        "### **5. What is Regularization in Logistic Regression? Why is it needed?**  \n",
        "Regularization prevents overfitting by adding a penalty to large coefficients. It ensures that the model generalizes well to unseen data. **L1 (Lasso) and L2 (Ridge) regularization** are commonly used.  \n",
        "\n",
        "### **6. Explain the difference between Lasso, Ridge, and Elastic Net Regression.**  \n",
        "- **Lasso (L1)**: Shrinks some coefficients to zero, performing feature selection.  \n",
        "- **Ridge (L2)**: Shrinks coefficients but does not eliminate them.  \n",
        "- **Elastic Net**: A mix of L1 and L2, useful when there are many correlated features.  \n",
        "\n",
        "### **7. When should we use Elastic Net instead of Lasso or Ridge?**  \n",
        "Elastic Net is preferred when **features are highly correlated**. It benefits from Lasso’s feature selection and Ridge’s ability to handle multicollinearity.  \n",
        "\n",
        "### **8. What is the impact of the regularization parameter (λ) in Logistic Regression?**  \n",
        "- **Higher λ** → More regularization → Simpler model, but may underfit.  \n",
        "- **Lower λ** → Less regularization → More complex model, but may overfit.  \n",
        "\n",
        "### **9. What are the key assumptions of Logistic Regression?**  \n",
        "- **No multicollinearity** among independent variables.  \n",
        "- **Logistic relationship** between independent variables and the log-odds.  \n",
        "- **Observations are independent** (no autocorrelation).  \n",
        "\n",
        "### **10. What are some alternatives to Logistic Regression for classification tasks?**  \n",
        "- Decision Trees  \n",
        "- Random Forest  \n",
        "- Support Vector Machines (SVM)  \n",
        "- Neural Networks  \n",
        "- Naïve Bayes  \n",
        "\n",
        "### **11. What are Classification Evaluation Metrics?**  \n",
        "- **Accuracy**: (TP + TN) / Total  \n",
        "- **Precision**: TP / (TP + FP)  \n",
        "- **Recall**: TP / (TP + FN)  \n",
        "- **F1 Score**: Harmonic mean of precision and recall  \n",
        "- **AUC-ROC**: Measures model discrimination ability  \n",
        "\n",
        "### **12. How does class imbalance affect Logistic Regression?**  \n",
        "Class imbalance skews predictions toward the majority class. Solutions include **resampling techniques (oversampling, undersampling)** and using **weighted loss functions**.  \n",
        "\n",
        "### **13. What is Hyperparameter Tuning in Logistic Regression?**  \n",
        "It involves adjusting parameters like **C (inverse of λ), solver, and penalty type** to improve model performance. Grid Search and Random Search are common techniques.  \n",
        "\n",
        "### **14. What are different solvers in Logistic Regression? Which one should be used?**  \n",
        "- **lbfgs**: Default, efficient for small to medium datasets.  \n",
        "- **liblinear**: Works well for small datasets, supports L1 regularization.  \n",
        "- **saga**: Best for large datasets, supports L1, L2, and Elastic Net.  \n",
        "\n",
        "### **15. How is Logistic Regression extended for multiclass classification?**  \n",
        "By using:  \n",
        "- **One-vs-Rest (OvR)**: Trains multiple binary classifiers.  \n",
        "- **Softmax Regression**: Generalizes logistic regression to multiple classes.  \n",
        "\n",
        "### **16. What are the advantages and disadvantages of Logistic Regression?**  \n",
        "**Advantages**: Simple, interpretable, works well for small datasets.  \n",
        "**Disadvantages**: Assumes a linear decision boundary, struggles with large and complex datasets.  \n",
        "\n",
        "### **17. What are some use cases of Logistic Regression?**  \n",
        "- Spam detection  \n",
        "- Credit scoring  \n",
        "- Disease diagnosis  \n",
        "- Fraud detection  \n",
        "\n",
        "### **18. What is the difference between Softmax Regression and Logistic Regression?**  \n",
        "- **Logistic Regression**: Used for **binary classification** (0 or 1).  \n",
        "- **Softmax Regression**: Used for **multiclass classification**, assigning probabilities across multiple categories.  \n",
        "\n",
        "### **19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**  \n",
        "- **OvR**: Works well for small datasets and binary-like problems.  \n",
        "- **Softmax**: Preferred when classes are **mutually exclusive** and dataset is large.  \n",
        "\n",
        "### **20. How do we interpret coefficients in Logistic Regression?**  \n",
        "Each coefficient represents the **log-odds change** for a unit increase in that predictor. A positive coefficient increases the likelihood of the event, while a negative one decreases it.  \n",
        "\n",
        "---  \n"
      ],
      "metadata": {
        "id": "jUx7-jsJZmNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical**"
      ],
      "metadata": {
        "id": "5lwqjSXrZ3D5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "wI-aFe8cadgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "n7mMflnCaeAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."
      ],
      "metadata": {
        "id": "Gk2VswePaf6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"L1 Regularization Model Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "sLJ9RXEcaj2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "h3Pr5l3_alwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"L2 Regularization Model Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(\"Model Coefficients:\", model.coef_)"
      ],
      "metadata": {
        "id": "Ph0MBcR_anTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "5zPbEC_hapDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Elastic Net Regularization Model Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "qyUaXo8TarQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
        "python\n",
        "Copy\n",
        "Edit\n"
      ],
      "metadata": {
        "id": "s4F6vaSQatiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Multiclass (OvR) Model Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "TLP5B9InawLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "e0N2oCaxayA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Model Accuracy: {grid_search.best_score_:.2f}\")"
      ],
      "metadata": {
        "id": "MhpGpS7ia0-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "gx1irpePa5Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(LogisticRegression(max_iter=200), X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Average Accuracy using Stratified K-Fold: {scores.mean():.2f}\")"
      ],
      "metadata": {
        "id": "6McD0FIVa7VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "2XeTuX5Ga9UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Model Accuracy from CSV dataset: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "Yf2QcVxPa-pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "E2ZQ_Oq0bAcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "param_dist = {'C': np.logspace(-4, 4, 20), 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "random_search = RandomizedSearchCV(LogisticRegression(max_iter=200), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "print(f\"Best Model Accuracy: {random_search.best_score_:.2f}\")"
      ],
      "metadata": {
        "id": "i15Vj6hgbPUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "9tmIc8IMbQ5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "model = OneVsOneClassifier(LogisticRegression(max_iter=200))\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"One-vs-One (OvO) Model Accuracy: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "id": "EIbAtGH1bSL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."
      ],
      "metadata": {
        "id": "lGz9gu7-bTy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dG6IzI3ybVKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score."
      ],
      "metadata": {
        "id": "k936Ww_EbWrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.2f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted'):.2f}\")"
      ],
      "metadata": {
        "id": "ysUI7yYRbYCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "yhEkjb1hbZ6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"Model Accuracy on Imbalanced Data: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "id": "Mp5BErr-bbO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance."
      ],
      "metadata": {
        "id": "-NwBhFlSbc2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('titanic.csv')\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"Titanic Dataset Model Accuracy: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "id": "JO8DoJt9bef4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "tW0nMojqbgAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "accuracy_without_scaling = model.score(X_test, y_test)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "accuracy_with_scaling = model.score(X_test_scaled, y_test)\n",
        "\n",
        "print(f\"Accuracy without Scaling: {accuracy_without_scaling:.2f}\")\n",
        "print(f\"Accuracy with Scaling: {accuracy_with_scaling:.2f}\")"
      ],
      "metadata": {
        "id": "R8ei8FG0bhcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "yKlgocvgbjIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.2f}\")"
      ],
      "metadata": {
        "id": "KgXyM0YhbkcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy."
      ],
      "metadata": {
        "id": "EizRNVUibmOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C=0.5, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"Custom Learning Rate Model Accuracy: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "id": "ceJYmf-Bbntl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python program to train Logistic Regression and identify important features based on model coefficients."
      ],
      "metadata": {
        "id": "OJBkUCkUbpXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = abs(model.coef_).sum(axis=0)\n",
        "features = pd.DataFrame({'Feature': df.columns[:-1], 'Importance': feature_importance})\n",
        "print(features.sort_values(by=\"Importance\", ascending=False))"
      ],
      "metadata": {
        "id": "ZEkuSR1sbq0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score."
      ],
      "metadata": {
        "id": "4OHjg3eAbsNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"Cohen’s Kappa Score: {cohen_kappa_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "DC2XPv5Pbtr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."
      ],
      "metadata": {
        "id": "lW40eazXbu_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "y_scores = model.decision_function(X_test)\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iq9WV40dbwT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy."
      ],
      "metadata": {
        "id": "3SQnHoWUbyO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Solver: {solver}, Accuracy: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "id": "J9kw52_pbzg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "3Nw7zrfdb0-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"Matthews Correlation Coefficient: {matthews_corrcoef(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "oHpmgxPRb2So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "PYImKhiRb4Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "raw_accuracy = model.score(X_test, y_test)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "scaled_accuracy = model.score(X_test_scaled, y_test)\n",
        "\n",
        "print(f\"Accuracy on Raw Data: {raw_accuracy:.2f}\")\n",
        "print(f\"Accuracy on Standardized Data: {scaled_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Rg_c7vilb5aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
      ],
      "metadata": {
        "id": "ZXj5T4V6b7K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "C_values = [0.01, 0.1, 1, 10]\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, max_iter=200)\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(f\"C={C}, Accuracy: {scores.mean():.2f}\")"
      ],
      "metadata": {
        "id": "vMeo9Ehrb8Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "uakJdkc_b9-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "joblib.dump(model, \"logistic_model.pkl\")\n",
        "\n",
        "loaded_model = joblib.load(\"logistic_model.pkl\")\n",
        "print(f\"Loaded Model Accuracy: {loaded_model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "id": "OhttxYzrcBhQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}