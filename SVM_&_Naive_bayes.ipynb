{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQlqmTNroel9EAgPHVNKUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaakash16/Python-Basics/blob/main/SVM_%26_Naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical**"
      ],
      "metadata": {
        "id": "CTNlXm5zIvGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. What is a Support Vector Machine (SVM)?**\n",
        "SVM is a supervised learning algorithm used for classification and regression. It finds the best hyperplane that separates different classes in a dataset.\n",
        "\n",
        "#### **2. What is the difference between Hard Margin and Soft Margin SVM?**\n",
        "- **Hard Margin**: No misclassification is allowed, requires perfectly separable data.\n",
        "- **Soft Margin**: Allows some misclassification to handle noisy and non-linearly separable data.\n",
        "\n",
        "#### **3. What is the mathematical intuition behind SVM?**\n",
        "SVM maximizes the margin between data points of different classes by solving an optimization problem using Lagrange multipliers.\n",
        "\n",
        "#### **4. What is the role of Lagrange Multipliers in SVM?**\n",
        "They help in transforming the constrained optimization problem into an unconstrained one, making it easier to solve.\n",
        "\n",
        "#### **5. What are Support Vectors in SVM?**\n",
        "Support vectors are the data points that are closest to the decision boundary and help define the margin.\n",
        "\n",
        "#### **6. What is a Support Vector Classifier (SVC)?**\n",
        "An SVC is an SVM model used for classification tasks.\n",
        "\n",
        "#### **7. What is a Support Vector Regressor (SVR)?**\n",
        "An SVR is an SVM model used for regression tasks by fitting the best hyperplane to predict continuous values.\n",
        "\n",
        "#### **8. What is the Kernel Trick in SVM?**\n",
        "It allows SVM to work in higher-dimensional space without explicitly transforming the data.\n",
        "\n",
        "#### **9. Compare Linear Kernel, Polynomial Kernel, and RBF Kernel.**\n",
        "- **Linear Kernel**: Best for linearly separable data.\n",
        "- **Polynomial Kernel**: Used for complex relationships.\n",
        "- **RBF Kernel**: Best for non-linearly separable data.\n",
        "\n",
        "#### **10. What is the effect of the C parameter in SVM?**\n",
        "Higher C values lead to lower bias but higher variance, making the model fit the data more strictly.\n",
        "\n",
        "#### **11. What is the role of the Gamma parameter in RBF Kernel SVM?**\n",
        "Higher gamma values make the model focus more on nearby points, capturing more complex patterns but increasing overfitting risk.\n",
        "\n",
        "#### **12. What is the Naïve Bayes classifier, and why is it called \"Naïve\"?**\n",
        "Naïve Bayes is a probabilistic classifier based on Bayes' theorem. It is \"naïve\" because it assumes that features are independent.\n",
        "\n",
        "#### **13. What is Bayes’ Theorem?**\n",
        "Bayes’ Theorem calculates the probability of an event based on prior knowledge of conditions related to the event.\n",
        "\n",
        "#### **14. Explain the differences between Gaussian Naïve Bayes, Multinomial Naïve Bayes, and Bernoulli Naïve Bayes.**\n",
        "- **Gaussian Naïve Bayes**: Assumes continuous data follows a Gaussian distribution.\n",
        "- **Multinomial Naïve Bayes**: Best for discrete data like word counts.\n",
        "- **Bernoulli Naïve Bayes**: Used for binary feature data.\n",
        "\n",
        "#### **15. When should you use Gaussian Naïve Bayes over other variants?**\n",
        "When working with continuous data that follows a normal distribution.\n",
        "\n",
        "#### **16. What are the key assumptions made by Naïve Bayes?**\n",
        "- Features are independent.\n",
        "- Each feature contributes equally to the outcome.\n",
        "\n",
        "#### **17. What are the advantages and disadvantages of Naïve Bayes?**\n",
        "**Advantages:** Fast, simple, works well with small datasets.\n",
        "**Disadvantages:** Assumes feature independence, which may not always be true.\n",
        "\n",
        "#### **18. Why is Naïve Bayes a good choice for text classification?**\n",
        "It performs well with high-dimensional sparse data and is computationally efficient.\n",
        "\n",
        "#### **19. Compare SVM and Naïve Bayes for classification tasks.**\n",
        "- **SVM**: Works well with complex boundaries but is computationally expensive.\n",
        "- **Naïve Bayes**: Works well with high-dimensional data and is faster.\n",
        "\n",
        "#### **20. How does Laplace Smoothing help in Naïve Bayes?**\n",
        "It prevents zero probability issues by adding a small value to all word counts."
      ],
      "metadata": {
        "id": "Oxw89HkHIzc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical**"
      ],
      "metadata": {
        "id": "Z6jvyLJ3I5Ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier on the Iris dataset and evaluate accuracy:"
      ],
      "metadata": {
        "id": "wwt3F59LI8lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uPMc9nFAI4Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train two SVM classifiers with Linear and RBF kernels on the Wine dataset, then\n",
        "compare their accuracies:"
      ],
      "metadata": {
        "id": "gWJlYnHWJLny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=42)\n",
        "\n",
        "clf_linear = SVC(kernel='linear')\n",
        "clf_rbf = SVC(kernel='rbf')\n",
        "\n",
        "clf_linear.fit(X_train, y_train)\n",
        "clf_rbf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_linear = clf_linear.predict(X_test)\n",
        "y_pred_rbf = clf_rbf.predict(X_test)\n",
        "\n",
        "print(\"Linear Kernel Accuracy:\", accuracy_score(y_test, y_pred_linear))\n",
        "print(\"RBF Kernel Accuracy:\", accuracy_score(y_test, y_pred_rbf))"
      ],
      "metadata": {
        "id": "VGSlO9KAJN-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Regressor (SVR) on a housing dataset and evaluate it using Mean\n",
        "Squared Error (MSE):"
      ],
      "metadata": {
        "id": "nrNQO_paJQ9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\n",
        "\n",
        "regressor = SVR()\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "8rnwDK_rJS46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier with a Polynomial Kernel and visualize the decision\n",
        "boundary:"
      ],
      "metadata": {
        "id": "e3H_krB4JVL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = np.random.randn(200, 2)\n",
        "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
        "\n",
        "svm_poly = SVC(kernel='poly', degree=3)\n",
        "svm_poly.fit(X, y)\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
        "Z = svm_poly.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dJEbKAV5JWx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Gaussian Naïve Bayes classifier on the Breast Cancer dataset and\n",
        "evaluate accuracy:"
      ],
      "metadata": {
        "id": "Q6SohmuqJZsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=42)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "mwBbZaYYJbwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Multinomial Naïve Bayes classifier for text classification using the 20\n",
        "Newsgroups dataset."
      ],
      "metadata": {
        "id": "vo_nc63XJeNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=['sci.space', 'rec.sport.baseball'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_counts = vectorizer.fit_transform(X_train)\n",
        "X_test_counts = vectorizer.transform(X_test)\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_counts, y_train)\n",
        "y_pred = mnb.predict(X_test_counts)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Q4t-6AskJfv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier with different C values and compare the decision\n",
        "boundaries visually."
      ],
      "metadata": {
        "id": "jrxdp3FDJiWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X = np.random.randn(200, 2)\n",
        "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
        "\n",
        "for C in [0.1, 1, 10]:\n",
        "    clf = SVC(kernel='linear', C=C)\n",
        "    clf.fit(X, y)\n",
        "    xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
        "    plt.title(f\"SVM with C={C}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fYk9d5bqJlAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Bernoulli Naïve Bayes classifier for binary classification on a dataset with\n",
        "binary features."
      ],
      "metadata": {
        "id": "PAr36Wv8JwfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=500, n_features=10, n_classes=2, random_state=42)\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X, y)\n",
        "y_pred = bnb.predict(X)\n",
        "print(\"Accuracy:\", accuracy_score(y, y_pred))"
      ],
      "metadata": {
        "id": "Y0apM4MyJyVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to apply feature scaling before training an SVM model and compare results with\n",
        "unscaled data."
      ],
      "metadata": {
        "id": "B_hcppasJ2Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy with Scaling:\", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "MwL9dzDBJ3e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Gaussian Naïve Bayes model and compare the predictions before and\n",
        "after Laplace Smoothing."
      ],
      "metadata": {
        "id": "J2PFa716J5CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnb_no_smoothing = GaussianNB(var_smoothing=1e-9)\n",
        "gnb_with_smoothing = GaussianNB(var_smoothing=1e-5)\n",
        "gnb_no_smoothing.fit(X_train, y_train)\n",
        "gnb_with_smoothing.fit(X_train, y_train)\n",
        "print(\"Accuracy without smoothing:\", gnb_no_smoothing.score(X_test, y_test))\n",
        "print(\"Accuracy with smoothing:\", gnb_with_smoothing.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "jm_PoXMoJ728"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier and use GridSearchCV to tune the hyperparameters (C,\n",
        "gamma, kernel)."
      ],
      "metadata": {
        "id": "_BC06wXxJ8Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best parameters:\", grid.best_params_)"
      ],
      "metadata": {
        "id": "SgbLKPilKBfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier on an imbalanced dataset and apply class weighting and\n",
        "check it improve accuracy."
      ],
      "metadata": {
        "id": "43fiEGaoKCgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = dict(zip(np.unique(y_train), compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)))\n",
        "clf = SVC(class_weight=class_weights)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy on imbalanced dataset:\", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "XUCACkHtKJ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to implement a Naïve Bayes classifier for spam detection using email data."
      ],
      "metadata": {
        "id": "s3_g3jRAKN8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "email_data = fetch_openml(name='spam', version=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(email_data.data, email_data.target, test_size=0.2, random_state=42)\n",
        "gnb.fit(X_train, y_train)\n",
        "print(\"Spam Detection Accuracy:\", gnb.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "HklI5gXlKQPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier and a Naïve Bayes Classifier on the same dataset and\n",
        "compare their accuracy."
      ],
      "metadata": {
        "id": "U6qHblycKT27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = SVC()\n",
        "svm_clf.fit(X_train, y_train)\n",
        "print(\"SVM Accuracy:\", svm_clf.score(X_test, y_test))\n",
        "print(\"Naive Bayes Accuracy:\", gnb.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "E-msZsAtKVen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to perform feature selection before training a Naïve Bayes classifier and compare\n",
        "results."
      ],
      "metadata": {
        "id": "vEqEx-Y4KYE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "X_new = SelectKBest(chi2, k=10).fit_transform(X_train, y_train)\n",
        "gnb.fit(X_new, y_train)\n",
        "print(\"Accuracy after feature selection:\", gnb.score(SelectKBest(chi2, k=10).fit_transform(X_test, y_test), y_test))"
      ],
      "metadata": {
        "id": "1_HPk7TVKY_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier using One-vs-Rest (OvR) and One-vs-One (OvO)\n",
        "strategies on the Wine dataset and compare their accuracy."
      ],
      "metadata": {
        "id": "5UEJ0ImcKayk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "\n",
        "ovr_svm = OneVsRestClassifier(SVC())\n",
        "ovo_svm = OneVsOneClassifier(SVC())\n",
        "\n",
        "ovr_svm.fit(X_train, y_train)\n",
        "ovo_svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"OvR Accuracy:\", ovr_svm.score(X_test, y_test))\n",
        "print(\"OvO Accuracy:\", ovo_svm.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "qyLsF2cLKcGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier using Linear, Polynomial, and RBF kernels on the Breast\n",
        "Cancer dataset and compare their accuracy."
      ],
      "metadata": {
        "id": "G67CCiURKfMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for kernel in ['linear', 'poly', 'rbf']:\n",
        "    clf = SVC(kernel=kernel)\n",
        "    clf.fit(X_train, y_train)\n",
        "    print(f\"{kernel} Kernel Accuracy:\", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "P23ilrCvKhLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier using Stratified K-Fold Cross-Validation and compute the\n",
        "average accuracy."
      ],
      "metadata": {
        "id": "S7BXiRrjKi9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(SVC(), X_train, y_train, cv=cv)\n",
        "print(\"Cross-validation scores:\", scores.mean())"
      ],
      "metadata": {
        "id": "HX7Ee9S0Kkmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Naïve Bayes classifier using different prior probabilities and compare\n",
        "performance."
      ],
      "metadata": {
        "id": "iy-B1A5-KmBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "priors = [[0.7, 0.3], [0.5, 0.5]]\n",
        "for prior in priors:\n",
        "    gnb = GaussianNB(priors=prior)\n",
        "    gnb.fit(X_train, y_train)\n",
        "    print(f\"Prior {prior} Accuracy:\", gnb.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "_ydYfMbEKzGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to perform Recursive Feature Elimination (RFE) before training an SVM Classifier and\n",
        "compare accuracy."
      ],
      "metadata": {
        "id": "XZFkmq_fKzhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "rfe = RFE(SVC(kernel='linear'), n_features_to_select=5)\n",
        "X_new = rfe.fit_transform(X_train, y_train)\n",
        "clf.fit(X_new, y_train)\n",
        "print(\"Accuracy after RFE:\", clf.score(rfe.transform(X_test), y_test))"
      ],
      "metadata": {
        "id": "Lrf8R6YeK1Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier and evaluate its performance using Precision, Recall, and\n",
        "F1-Score instead of accuracy."
      ],
      "metadata": {
        "id": "9Lgl6D27K3pY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "p6tVh3XMK5sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Naïve Bayes Classifier and evaluate its performance using Log Loss\n",
        "(Cross-Entropy Loss)."
      ],
      "metadata": {
        "id": "eehVKO6VK8qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "y_prob = gnb.predict_proba(X_test)\n",
        "print(\"Log Loss:\", log_loss(y_test, y_prob))"
      ],
      "metadata": {
        "id": "qbhvsRngK-ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier and visualize the Confusion Matrix using seaborn."
      ],
      "metadata": {
        "id": "_VyWaya-LBUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yXpAXS-yLC0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Regressor (SVR) and evaluate its performance using Mean Absolute\n",
        "Error (MAE) instead of MSE."
      ],
      "metadata": {
        "id": "5EY9XgjbLE7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "y_pred = regressor.predict(X_test)\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "niogPW5QLGT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Naïve Bayes classifier and evaluate its performance using the ROC-AUC\n",
        "score."
      ],
      "metadata": {
        "id": "iyaLz7-ELIAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_prob = gnb.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))"
      ],
      "metadata": {
        "id": "4xEi28NgLJMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train an SVM Classifier and visualize the Precision-Recall Curve."
      ],
      "metadata": {
        "id": "hCxsTYOuLKoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mdNYrkfvLMTx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}