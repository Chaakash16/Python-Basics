{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUWSPrTIwIc2wB0aFaBdTm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaakash16/Python-Basics/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Regression Questions & Answers**"
      ],
      "metadata": {
        "id": "bxQxDtjG2zzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **What is Simple Linear Regression?**  \n",
        "   Simple Linear Regression models the relationship between two variables using a straight-line equation: \\( Y = mX + c \\).  \n",
        "\n",
        "2. **What are the key assumptions of Simple Linear Regression?**  \n",
        "   - Linearity  \n",
        "   - Independence of errors  \n",
        "   - Homoscedasticity (constant variance of errors)  \n",
        "   - Normal distribution of residuals  \n",
        "\n",
        "3. **What does the coefficient \\( m \\) represent in the equation \\( Y = mX + c \\)?**  \n",
        "   It represents the slope, showing how much Y changes for a one-unit increase in X.  \n",
        "\n",
        "4. **What does the intercept \\( c \\) represent in the equation \\( Y = mX + c \\)?**  \n",
        "   It is the value of Y when X = 0, representing the starting point of the regression line.  \n",
        "\n",
        "5. **How do we calculate the slope \\( m \\) in Simple Linear Regression?**  \n",
        "   \\[\n",
        "   m = \\frac{\\sum (X - \\bar{X}) (Y - \\bar{Y})}{\\sum (X - \\bar{X})^2}\n",
        "   \\]  \n",
        "\n",
        "6. **What is the purpose of the least squares method in Simple Linear Regression?**  \n",
        "   It minimizes the sum of squared residuals to find the best-fit line.  \n",
        "\n",
        "7. **How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**  \n",
        "   R² measures the proportion of variance in Y explained by X, with values from 0 to 1.  \n",
        "\n",
        "8. **What is Multiple Linear Regression?**  \n",
        "   It extends Simple Linear Regression by modeling the relationship between Y and multiple independent variables.  \n",
        "\n",
        "9. **What is the main difference between Simple and Multiple Linear Regression?**  \n",
        "   Simple Linear Regression has one independent variable, while Multiple Linear Regression has two or more.  \n",
        "\n",
        "10. **What are the key assumptions of Multiple Linear Regression?**  \n",
        "    - Linearity  \n",
        "    - Independence of errors  \n",
        "    - No multicollinearity  \n",
        "    - Homoscedasticity  \n",
        "    - Normality of residuals  \n",
        "\n",
        "11. **What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**  \n",
        "    Heteroscedasticity means that residual variance is not constant, which can lead to unreliable predictions.  \n",
        "\n",
        "12. **How can you improve a Multiple Linear Regression model with high multicollinearity?**  \n",
        "    - Remove highly correlated variables  \n",
        "    - Use Principal Component Analysis (PCA)  \n",
        "    - Apply Ridge or Lasso regression  \n",
        "\n",
        "13. **What are some common techniques for transforming categorical variables for use in regression models?**  \n",
        "    - One-hot encoding  \n",
        "    - Label encoding  \n",
        "    - Dummy variables  \n",
        "\n",
        "14. **What is the role of interaction terms in Multiple Linear Regression?**  \n",
        "    Interaction terms capture combined effects of two or more independent variables on Y.  \n",
        "\n",
        "15. **How can the interpretation of the intercept differ between Simple and Multiple Linear Regression?**  \n",
        "    In Multiple Linear Regression, the intercept represents Y when all independent variables are zero, which may not always be meaningful.  \n",
        "\n",
        "16. **What is the significance of the slope in regression analysis, and how does it affect predictions?**  \n",
        "    The slope indicates how a one-unit increase in X impacts Y, determining the strength of the relationship.  \n",
        "\n",
        "17. **How does the intercept in a regression model provide context for the relationship between variables?**  \n",
        "    It shows the expected value of Y when all independent variables are zero.  \n",
        "\n",
        "18. **What are the limitations of using R² as a sole measure of model performance?**  \n",
        "    - It does not indicate causality  \n",
        "    - It does not consider model complexity  \n",
        "    - High R² does not guarantee a good predictive model  \n",
        "\n",
        "19. **How would you interpret a large standard error for a regression coefficient?**  \n",
        "    It suggests high variability in coefficient estimation, indicating low reliability.  \n",
        "\n",
        "20. **How can heteroscedasticity be identified in residual plots, and why is it important to address it?**  \n",
        "    It appears as a funnel shape in residual plots; addressing it improves model reliability.  \n",
        "\n",
        "21. **What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**  \n",
        "    It suggests that some independent variables do not significantly contribute to the model.  \n",
        "\n",
        "22. **Why is it important to scale variables in Multiple Linear Regression?**  \n",
        "    Scaling improves model stability and performance, especially when using gradient-based optimization.  \n",
        "\n",
        "23. **What is polynomial regression?**  \n",
        "    It extends linear regression by fitting a polynomial equation to the data instead of a straight line.  \n",
        "\n",
        "24. **How does polynomial regression differ from linear regression?**  \n",
        "    Polynomial regression models curved relationships, while linear regression models straight-line relationships.  \n",
        "\n",
        "25. **When is polynomial regression used?**  \n",
        "    When the relationship between X and Y is nonlinear.  \n",
        "\n",
        "26. **What is the general equation for polynomial regression?**  \n",
        "    \\[\n",
        "    Y = a_0 + a_1X + a_2X^2 + ... + a_nX^n\n",
        "    \\]  \n",
        "\n",
        "27. **Can polynomial regression be applied to multiple variables?**  \n",
        "    Yes, it can be extended to multiple independent variables.  \n",
        "\n",
        "28. **What are the limitations of polynomial regression?**  \n",
        "    - Overfitting with high-degree polynomials  \n",
        "    - Sensitive to outliers  \n",
        "    - Complex interpretation  \n",
        "\n",
        "29. **What methods can be used to evaluate model fit when selecting the degree of a polynomial?**  \n",
        "    - Adjusted R²  \n",
        "    - Cross-validation  \n",
        "    - Mean Squared Error (MSE)  \n",
        "\n",
        "30. **Why is visualization important in polynomial regression?**  \n",
        "    It helps understand the shape of the fitted curve and detect overfitting.  \n",
        "\n",
        "31. **How is polynomial regression implemented in Python?**  \n",
        "    Using `PolynomialFeatures` from `sklearn.preprocessing` and `LinearRegression` from `sklearn.linear_model`.  "
      ],
      "metadata": {
        "id": "wGc17Hxk2zpx"
      }
    }
  ]
}